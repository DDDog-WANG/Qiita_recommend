{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from urllib.parse import urlparse\n",
    "from sqlalchemy import create_engine\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "#dbserver_sampleの中身を書き換えて、ファイル名をdbserver.txtに変更\n",
    "#dbserver.txtからdbのpathを読み込む\n",
    "\n",
    "db_path = open('dbserver.txt', 'r').read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018-07-31.csv\n",
      "2018-07-15.csv\n",
      "2019-01-15.csv\n"
     ]
    }
   ],
   "source": [
    "#/data/results以下のcsvファイル名を取得\n",
    "import pathlib\n",
    "p_temp = pathlib.Path('data/').glob('20*.csv')\n",
    "p_list=list()\n",
    "for p in p_temp:\n",
    "    p_list.append(p.name)\n",
    "    print(p.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#複数のcsvファイルの送信\n",
    "# import pathlib\n",
    "# from urllib.parse import urlparse\n",
    "# from sqlalchemy.sql import text\n",
    "# url = urlparse(db_path)\n",
    "# conn = create_engine('mysql://{user}:{password}@{host}:{port}/{database}?charset=utf8'.format(host = url.hostname, port=url.port, user = url.username, password= url.password, database = url.path[1:]),encoding='utf-8')\n",
    "# table='raw_from_api'\n",
    "# p_temp = pathlib.Path('data/results').glob('20*.csv')\n",
    "# error = 0\n",
    "# count = 0\n",
    "# for p in p_list:\n",
    "#     count +=1\n",
    "#     print(str(count)+':'+p)\n",
    "#     df = pd.read_csv('./data/results//'+p)\n",
    "#     for index, row in df.iterrows():\n",
    "#         try:\n",
    "#             # sql = text(\"\"\"INSERT INTO {} \n",
    "#             # (article_id,created_at,updated_at,likes_count,comments_count,tags_str,user_id,user_permanent_id,url,html,markdown) \n",
    "#             # VALUES(:article_id,:created_at,:updated_at,:likes_count,:comments_count,:tags_str,:user_id,:user_permanent_id,:url,:html,:markdown) \n",
    "#             # ON DUPLICATE KEY UPDATE html=:html,markdown=:markdown;\"\"\".format(table))\n",
    "#             sql = text(\"\"\"update {} set title=:title where article_id=:article_id;\"\"\".format(table))\n",
    "#             para = {\n",
    "#         \"article_id\":row['id'], \"created_at\":row['created_at'],\"updated_at\":row['updated_at'],\n",
    "#         \"likes_count\":row['likes_count'], \"comments_count\":row['comments_count'],\n",
    "#         \"tags_str\":row['tags_str'],\"user_id\":row['user_id'],\"user_permanent_id\":row['user_permanent_id'],\n",
    "#         \"url                                'ren# dered_body'],'markdown':row['body']}  \n",
    "\n",
    "#             para = {\"title\":row['title'], \"article_id\":row['id']}            \n",
    "#             result = conn.execute(sql,**para)\n",
    "#         #エラー処理（例外は飛ばす）\n",
    "#         except Exception as e:\n",
    "#             error +=1\n",
    "#             print('=== エラー内容 ===')\n",
    "#             print('type:' + str(type(e)))\n",
    "#             print('args:' + str(e.args))\n",
    "#             print('e自身:' + str(e))\n",
    "#             if error >= 10:\n",
    "#                 break\n",
    "#             pass\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#db接続しcsvのデータを重複なしでinsertする（重複がある場合はupdated_at,html,markdownを更新）\n",
    "\n",
    "# from sqlalchemy.sql import text\n",
    "\n",
    "# #csvファイル読み込み\n",
    "# df = pd.read_csv('./data/results/2011-10-15.csv')\n",
    "# url = urlparse(db_path)\n",
    "# conn = create_engine('mysql://{user}:{password}@{host}:{port}/{database}?charset=utf8'.format(host = url.hostname, port=url.port, user = url.username, password= url.password, database = url.path[1:]),encoding='utf-8')\n",
    "# table='raw_from_api'\n",
    "# for index, row in df.iterrows():\n",
    "#         sql = text(\"\"\"INSERT INTO {} \n",
    "#         (article_id,created_at,updated_at,likes_count,comments_count,tags_str,user_id,user_permanent_id,url,html,markdown) \n",
    "#         VALUES(:article_id,:created_at,:updated_at,:likes_count,:comments_count,:tags_str,:user_id,:user_permanent_id,:url,:html,:markdown) \n",
    "#         ON DUPLICATE KEY UPDATE html=:html,markdown=:markdown;\"\"\".format(table))\n",
    "\n",
    "#         para = {\n",
    "#                 \"article_id\":row['id'], \"created_at\":row['created_at'],\"updated_at\":row['updated_at'],\n",
    "#                 \"likes_count\":row['likes_count'], \"comments_count\":row['comments_count'],\n",
    "#                 \"tags_str\":row['tags_str'],\"user_id\":row['user_id'],\"user_permanent_id\":row['user_permanent_id'],\n",
    "#                 \"url\":row['url'],\"html\":row['rendered_body'],'markdown':row['body']}            \n",
    "#         result = conn.execute(sql,**para)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dbに接続し、テーブルから取ってきたデータをdataframeに変換\n",
    "# from urllib.parse import urlparse\n",
    "# from sqlalchemy import create_engine\n",
    "# from sqlalchemy.sql import text\n",
    "# import pandas as pd\n",
    "# from datetime import datetime, date, timezone, timedelta\n",
    "\n",
    "# url = urlparse(db_path) \n",
    "\n",
    "# conn = create_engine('mysql://{user}:{password}@{host}:{port}/{database}?charset=utf8'.format(host = url.hostname, port=url.port, user = url.username, password= url.password, database = url.path[1:]),encoding='utf-8')\n",
    "\n",
    "# table='raw_from_api'\n",
    "# sql_read=text(\"select * from qiita_db.raw_from_api where likes_count = {};\".format(50))\n",
    "# #sql_read=text(\"select * from qiita_db.raw_from_api where created_at = '{}';\".format('2019-01-01 10:53:44'))\n",
    "# # #sql_read=text(\"select * from qiita_db.raw_from_api where created_at between'{}' and '{}';\".format('2019-01-01 00:00:00','2019-02-01 00:00:00'))\n",
    "\n",
    "# df = pd.read_sql(sql# _read, conn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 587 entries, 0 to 586\n",
      "Data columns (total 13 columns):\n",
      "id                   587 non-null int64\n",
      "article_id           587 non-null object\n",
      "title                587 non-null object\n",
      "created_at           587 non-null datetime64[ns]\n",
      "updated_at           587 non-null datetime64[ns]\n",
      "likes_count          587 non-null int64\n",
      "comments_count       587 non-null int64\n",
      "tags_str             587 non-null object\n",
      "user_id              587 non-null object\n",
      "user_permanent_id    587 non-null int64\n",
      "url                  587 non-null object\n",
      "html                 587 non-null object\n",
      "markdown             587 non-null object\n",
      "dtypes: datetime64[ns](2), int64(4), object(7)\n",
      "memory usage: 59.7+ KB\n"
     ]
    }
   ],
   "source": [
    "# df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 接続例2\n",
    "# !pip install mysql-connector-python-rf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from urllib.parse import urlparse\n",
    "import mysql.connector\n",
    "\n",
    "url = urlparse(db_path)\n",
    "\n",
    "conn = mysql.connector.connect(\n",
    "    host = url.hostname or 'localhost',\n",
    "    port = url.port or 3306,\n",
    "    user = url.username or 'root',\n",
    "    password = url.password or '',\n",
    "    database = url.path[1:],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conn.is_connected()  #=> Bool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#実行結果を辞書型で返す\n",
    "cur = conn.cursor(dictionary=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1:2018-07-31.csv\n",
      "2:2018-07-15.csv\n",
      "3:2019-01-15.csv\n"
     ]
    }
   ],
   "source": [
    "#tokensの更新 paraのtokensを変更\n",
    "import pathlib\n",
    "p_temp = pathlib.Path('data/').glob('20*.csv')\n",
    "error = 0\n",
    "count = 0\n",
    "for p in p_list:\n",
    "    count +=1\n",
    "    print(str(count)+':'+p)\n",
    "    df = pd.read_csv('./data//'+p)\n",
    "    for index, row in df.iterrows():\n",
    "        try:\n",
    "            sql =\"update raw_from_api set tokens=%s where article_id=%s;\"\n",
    "            para = ['tokens', row['id']]         \n",
    "            result = cur.execute(sql,para)\n",
    "            conn.commit()\n",
    "        #エラー処理（例外は飛ばす）\n",
    "        except Exception as e:\n",
    "            conn.rollback()\n",
    "            error +=1\n",
    "            print('=== エラー内容 ===')\n",
    "            print('type:' + str(type(e)))\n",
    "            print('args:' + str(e.args))\n",
    "            print('e自身:' + str(e))\n",
    "            if error >= 10:\n",
    "                break\n",
    "            pass\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'toknes': 'Release Build?'},\n",
       " {'toknes': '[React][TypeScript]create-react-app + tslint + prettier'},\n",
       " {'toknes': 'Qiita API で自分のユーザー情報を取得するRubyのスクリプト例'},\n",
       " {'toknes': 'GitHubとGitLab両方でプライベートリポジトリを並行運用してみよう'},\n",
       " {'toknes': 'herokuで heroku run rake db:migrate 打って Mysql2::Error::ConnectionError になったときの対処'}]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#データ取得例\n",
    "cur.execute(\"select title toknes from qiita_db.raw_from_api where tokens = {} limit 5;\".format('tokens'))\n",
    "cur.fetchall()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
